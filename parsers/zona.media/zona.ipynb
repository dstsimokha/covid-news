{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as xet\n",
    "import requests as req\n",
    "import time\n",
    "import glob\n",
    "import csv\n",
    "import regex\n",
    "import tqdm\n",
    "import pytz\n",
    "import numpy as np\n",
    "import io\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sitemap(fn):\n",
    "\n",
    "    xml = xet.parse(fn)\n",
    "    xml_root = xml.getroot()\n",
    "    news_list = []\n",
    "    \n",
    "    for news in xml_root:\n",
    "        try:\n",
    "            result = {}\n",
    "            result['url'] = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc').text\n",
    "            lastmod = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}lastmod')\n",
    "            if lastmod is not None:\n",
    "                result['lastmod'] = lastmod.text\n",
    "\n",
    "            #title = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}news:title').text\n",
    "            #keywords = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}news:keywords').text\n",
    "            #news_list.append(dict(zip(['url', 'lastmod'], [url, lastmod])))\n",
    "            news_list.append(result)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitemaps = parse_sitemap(io.StringIO(req.get('https://zona.media/sitemap.xml').content.decode()))\n",
    "sitemaps_filtered = []\n",
    "for sitemap in sitemaps:\n",
    "    if re.search(r'2020|2019', sitemap['url']):\n",
    "        sitemaps_filtered.append(sitemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-73c316e576b5>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for fn in tqdm.tqdm_notebook(sitemaps_filtered):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e29a1ba657c4282bf4354e7e87b92ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_db = []\n",
    "\n",
    "for fn in tqdm.tqdm_notebook(sitemaps_filtered):\n",
    "    s1 = time.time()\n",
    "\n",
    "    try:\n",
    "        text = io.StringIO(req.get(fn['url']).content.decode())\n",
    "        news = parse_sitemap(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    news_db += news\n",
    "    s2 = time.time()\n",
    "    time.sleep(max(1 - s2 + s1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>lastmod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://zona.media/news/2020/12/13/girl</td>\n",
       "      <td>2020-12-13 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://zona.media/news/2020/12/13/vnkmt</td>\n",
       "      <td>2020-12-13 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://zona.media/news/2020/12/13/bunker</td>\n",
       "      <td>2020-12-13 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://zona.media/news/2020/12/13/putin</td>\n",
       "      <td>2020-12-13 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://zona.media/chronicle/koronavirus_dcmbr</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              url                   lastmod\n",
       "0         https://zona.media/news/2020/12/13/girl 2020-12-13 00:00:00+00:00\n",
       "1        https://zona.media/news/2020/12/13/vnkmt 2020-12-13 00:00:00+00:00\n",
       "2       https://zona.media/news/2020/12/13/bunker 2020-12-13 00:00:00+00:00\n",
       "3        https://zona.media/news/2020/12/13/putin 2020-12-13 00:00:00+00:00\n",
       "4  https://zona.media/chronicle/koronavirus_dcmbr                       NaT"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(news_db)\n",
    "df['lastmod'] = pd.to_datetime(pd.Series(df.url.str.extract(r'(\\d{4,4}\\/\\d+\\/\\d+)').values.ravel()), format='%Y/%m/%d', utc=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7125, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.lastmod >= '2019-11-01')].to_json('news_mediazona.json', date_unit='s', date_format='iso')\n",
    "df[(df.lastmod >= '2019-11-01')].shape\n",
    "#df[(df.lastmod >= '2018-01-01') & (df.lastmod < '2019-07-01')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news(text):\n",
    "    soup = BeautifulSoup(text, features='lxml')\n",
    "    \n",
    "    news_text = ''\n",
    "    news_body = soup.find(name='div', attrs={'class': 'mz-publish__wrapper'})\n",
    "    \n",
    "    if news_body:\n",
    "        bad = news_body.find_all(name=['script', 'iframe', 'svg'])\n",
    "        if bad:\n",
    "            [tag.decompose() for tag in bad]\n",
    "        \n",
    "        news_ps = news_body.find_all(name=['p', 'h2', 'li'])\n",
    "        if news_ps:\n",
    "            news_text += \" \" + \" \".join([news_p.get_text(\" \", strip=True) for news_p in news_ps])\n",
    "        news_text = re.sub(r'[\\n\\r]+', ' ', news_text)\n",
    "    \n",
    "    \n",
    "    description_elem = soup.find(name=\"meta\", attrs={'name': \"description\"})\n",
    "    description = re.sub(r'[\\n\\r]+|<[^>]+>', ' ', description_elem.get('content')) if description_elem else ''\n",
    "        \n",
    "    return {'news_text': news_text, 'description': description}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_text': ' В больницу с обморожением доставили новосибирского рабочего, которые трое суток провел на площадке строительного крана, требуя выплаты зарплаты. С крана мужчину сняли спасатели, пишет «МБХ-медиа». Работавший на стройке новосибирец забрался на 90-метровый кран утром 28 декабря. «Долг по зарплате у него 140 тысяч — за март, за апрель, сентябрь и август. Сегодня свет отрубили на кране, чтобы слез, но он не собирается, ему нечего терять, семьи у него нет. Никто не реагирует на него», — рассказывал «НГС.Новости» коллега строителя. Работодатель новосибирца — застройщик «ПТК-30». Сотрудники этой компании уже не первый раз требуют погасить долги по зарплате: двое строителей требовали выплатить им зарплату в августе, в октябре на башенный кран забрались десять человек, в декабре — трое . Раз в неделю наши авторы делятся своими впечатлениями от главных событий и текстов',\n",
       " 'description': 'В больницу с обморожением доставили новосибирского рабочего, которые трое суток провел на площадке строительного крана, ...'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_news(req.get(df.iloc[-1].url).content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
