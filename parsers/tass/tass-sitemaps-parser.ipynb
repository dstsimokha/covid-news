{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as xet\n",
    "import requests as req\n",
    "import time\n",
    "import glob\n",
    "import csv\n",
    "import regex\n",
    "import tqdm\n",
    "import pytz\n",
    "import io\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sitemap(fn):\n",
    "\n",
    "    xml = xet.parse(fn)\n",
    "    xml_root = xml.getroot()\n",
    "    news_list = []\n",
    "    \n",
    "    for news in xml_root:\n",
    "        try:\n",
    "            result = {}\n",
    "            result['url'] = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc').text\n",
    "            lastmod = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}lastmod')\n",
    "            if lastmod is not None:\n",
    "                result['lastmod'] = lastmod.text\n",
    "\n",
    "            #title = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}news:title').text\n",
    "            #keywords = news.find('{http://www.sitemaps.org/schemas/sitemap/0.9}news:keywords').text\n",
    "            #news_list.append(dict(zip(['url', 'lastmod'], [url, lastmod])))\n",
    "            news_list.append(result)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitemaps = parse_sitemap(io.StringIO(req.get('https://tass.ru/sitemap.xml').content.decode()))\n",
    "len(sitemaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-1b27f3d996d8>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for fn in tqdm.tqdm_notebook(sitemaps):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19876bf61cd44920aee8bda34d9ba840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=53.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_db = []\n",
    "\n",
    "for fn in tqdm.tqdm_notebook(sitemaps):\n",
    "    s1 = time.time()\n",
    "\n",
    "    try:\n",
    "        text = io.StringIO(req.get(fn['url']).content.decode())\n",
    "        news = parse_sitemap(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    news_db += news\n",
    "    s2 = time.time()\n",
    "    time.sleep(max(1 - s2 + s1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>lastmod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://tass.ru/sport/10242051</td>\n",
       "      <td>2020-12-12 13:15:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://tass.ru/sport/10242087</td>\n",
       "      <td>2020-12-12 13:20:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://tass.ru/mezhdunarodnaya-panorama/10241989</td>\n",
       "      <td>2020-12-12 13:22:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://tass.ru/mezhdunarodnaya-panorama/10242079</td>\n",
       "      <td>2020-12-12 13:25:48+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://tass.ru/sport/10242125</td>\n",
       "      <td>2020-12-12 13:29:54+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url                   lastmod\n",
       "0                     https://tass.ru/sport/10242051 2020-12-12 13:15:26+00:00\n",
       "1                     https://tass.ru/sport/10242087 2020-12-12 13:20:05+00:00\n",
       "2  https://tass.ru/mezhdunarodnaya-panorama/10241989 2020-12-12 13:22:30+00:00\n",
       "3  https://tass.ru/mezhdunarodnaya-panorama/10242079 2020-12-12 13:25:48+00:00\n",
       "4                     https://tass.ru/sport/10242125 2020-12-12 13:29:54+00:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(news_db)\n",
    "df['lastmod'] = pd.to_datetime(df['lastmod'], format='%Y-%m-%dT%H:%M:%S', utc=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257124, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.lastmod >= '2019-11-01')].to_json('news_tass.json', date_unit='s', date_format='iso')\n",
    "df[(df.lastmod >= '2019-11-01')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_news(text):\n",
    "    soup = BeautifulSoup(text, features='lxml')\n",
    "    \n",
    "    news_text = ''\n",
    "    lead = soup.find(name='div', attrs={'class': 'news-header__lead'})\n",
    "    \n",
    "    if lead:\n",
    "        news_text += lead.get_text(' ', strip=True)\n",
    "\n",
    "    news_body = soup.find(name='div', attrs={'class': 'text-content'})\n",
    "    if news_body:\n",
    "        news_ps = news_body.find_all(name='p')\n",
    "        if news_ps:\n",
    "            news_text += \" \" + \" \".join([news_p.get_text(\" \", strip=True) for news_p in news_ps])\n",
    "    \n",
    "    news_text = re.sub(r'[\\n\\r]+', ' ', news_text)\n",
    "\n",
    "    tags_elems = soup.find_all(name=\"a\", attrs={'class': \"tags__item\"})\n",
    "    if tags_elems:\n",
    "        tags = [re.sub(r'[\\n\\r]+', ' ', tag.get_text(\" \", strip=True)) for tag in tags_elems]\n",
    "        tags = \", \".join(tags)\n",
    "    else:\n",
    "        tags = ''\n",
    "    \n",
    "    description_elem = soup.find(name=\"meta\", attrs={'name': \"description\"})\n",
    "    description = re.sub(r'[\\n\\r]+', ' ', description_elem.get('content')).replace(u'\\xa0', u' ') if description_elem else ''\n",
    "        \n",
    "    return {'news_text': news_text, 'tags': tags, 'description': description}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_text': 'Как сообщила главный внештатный терапевт ведомства Оксана Драпкина, речь идет о первом этапе диспансеризации, куда включен и онкоскрининг САНКТ-ПЕТЕРБУРГ, 8 июня. /ТАСС/. Большинство регионов уже готовы проводить первый этап диспансеризации, включающий профилактический осмотр, за один день, сообщила в субботу на полях Петербургского международного экономического форума главный внештатный терапевт Минздрава России Оксана Драпкина порталу \"Будущее России. Национальные проекты\" , оператором которого является ТАСС. Ранее Минздрав РФ опубликовал на федеральном портале проектов нормативных правовых актов проект приказа, дополняющий порядок прохождения профилактических осмотров и диспансеризации сроком в один день. \"Мы говорим про первый этап диспансеризации, туда включен <…> и онкоскрининг. Реально все сдать, прийти и сделать все исследования в рамках первого этапа диспансеризации - это реально. По всем субъектам ситуация разная, но в принципе, если наладить и быть уверенным, что оптимизирована маршрутизация и все логично, то это реально уже для большинства субъектов\", - сказала она. Единый порядок проведения профилактических медицинских осмотров и диспансеризации, вступивший в силу в мае, предусматривает ряд качественных изменений в профилактических мероприятиях. В рамках национальных проектов \"Здравоохранение\" и \"Демография\" Минздрав России выстраивает систему профилактики, при которой выявление хронических неинфекционных заболеваний (сердечно-сосудистых, онкологических, эндокринных и ряда других) на ранней стадии и их корректирование позволит избежать развития осложнений в будущем. Создаваемая система медицинской профилактики позволит в рамках федерального проекта \"Развитие системы оказания первичной медико-санитарной помощи\" нацпроекта \"Здравоохранение\" увеличить за шесть лет охват профилактическими мероприятиями до 70% россиян ежегодно. Выявление и корректирование хронических заболеваний до того, как они станут жизнеугрожающими, внесет существенный вклад в снижение показателей смертности трудоспособного населения, летальности от сердечно-сосудистых и онкологических заболеваний. Петербургский международный экономический форум проходит с 6 по 8 июня. Мероприятия форума объединены девизом \"Формируя повестку устойчивого развития\". Организатор - фонд \"Росконгресс\". ТАСС - информационный партнер, официальное фотохост-агентство и оператор Зоны презентаций ПМЭФ при поддержке консалтинговой компании EY и Консультативного совета по иностранным инвестициям в России.',\n",
       " 'tags': 'Россия, ПМЭФ-2019',\n",
       " 'description': 'Как сообщила главный внештатный терапевт ведомства Оксана Драпкина, речь идет о первом этапе диспансеризации, куда включен и онкоскрининг'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_news(req.get('https://tass.ru/nacionalnye-proekty/6528159').content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
